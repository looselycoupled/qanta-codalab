{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import os\n",
    "from qanta.tfidf import TfidfGuesser\n",
    "from qanta.models.dan import DanGuesser, DanModel, DanEncoder, datasets\n",
    "from qanta.models.timer import Timer\n",
    "\n",
    "from numpy import dot\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from IPython.display import display\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import torchtext.vocab as vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Train/Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../src/qanta\")\n",
    "train_data, dev_data, test_data = datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View single record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One work by this author uses printing, gunpowder, and the compass as symbols of personal ambition, national ambition, and the ambition of the human race to extend its grasp. This thinker described three forms of false learning as \"delicate\", \"contentious\", and \"fantastical\" in categorizing the \"distempers\" that impede academic progress. This thinker imagined a utopian university called Salomon\\'s House, and he likened received systems of philosophy to stage plays that misrepresent the world, and thus labeled them \"idols of the theatre\". This author of The New Atlantis established the doctrine of inductive, empirical methodology. For 10 points, name this 17th-century English philosopher who wrote Novum Organum and spearheaded the Scientific Revolution.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = test_data[0]\n",
    "question_text = question[\"text\"]\n",
    "ans = question[\"page\"]\n",
    "question_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-06 03:02:08,709 [INFO ]  Loading vectors from .vector_cache/glove.6B.100d.txt.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 words\n"
     ]
    }
   ],
   "source": [
    "glove100 = vocab.GloVe(name='6B', dim=100)\n",
    "print('Loaded {} words'.format(len(glove100.itos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-06 03:02:10,400 [INFO ]  Loading vectors from .vector_cache/glove.6B.200d.txt.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 words\n"
     ]
    }
   ],
   "source": [
    "glove = vocab.GloVe(name='6B', dim=200)\n",
    "print('Loaded {} words'.format(len(glove.itos)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility to find target word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def target_word_vector(text):\n",
    "    word = target_word(text)\n",
    "    if not word: \n",
    "        return None\n",
    "    \n",
    "    if word in glove.stoi:\n",
    "        return glove.vectors[glove.stoi[word]]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "def target_word(text):\n",
    "    if \"this\" not in text and \"This\" not in text and \"these\" not in text and \"These\" not in text:\n",
    "        return None\n",
    "\n",
    "    determiner_found = False\n",
    "    determiners = (\"this\", \"these\", \"This\", \"These\")\n",
    "    first_sent = sent_tokenize(text)[0]\n",
    "    tags = pos_tag(word_tokenize(first_sent))\n",
    "    for word, pos in tags:\n",
    "        if determiner_found:\n",
    "            if pos in [\"NN\", \"NNS\"]:\n",
    "                return word\n",
    "        else:\n",
    "            if word in determiners:\n",
    "                determiner_found = True\n",
    "            \n",
    "\n",
    "# for q in test_data[:2]:\n",
    "#     print(target_word(q[\"text\"]))\n",
    "#     print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3818499280654741"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def sim(w1, w2, embs):\n",
    "    wv1, wv2 = embs.vectors[embs.stoi[w1]], embs.vectors[embs.stoi[w2]]\n",
    "    return dot(wv1,wv2)/ (sqrt(dot(wv1,wv1))*sqrt(dot(wv2,wv2)))\n",
    "\n",
    "sim(\"conflict\", \"rebellions\", glove100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/allen/.pyenv/versions/cmsc723/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.2 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/allen/.pyenv/versions/cmsc723/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.2 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "tfidf_guesser = TfidfGuesser.load(stem=True)\n",
    "dan_guesser = DanGuesser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guess and Buzz code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUZZ_NUM_GUESSES = 10\n",
    "BUZZ_THRESHOLD = .3\n",
    "def guess_and_buzz(tfidf_model, dan_model, question_text):\n",
    "    tfidf_guesses = tfidf_model.guess([question_text], BUZZ_NUM_GUESSES)[0]\n",
    "    dan_guesses = dan_model.guess(question_text, BUZZ_NUM_GUESSES)\n",
    "\n",
    "    question_len = len(question_text.split(\" \"))\n",
    "\n",
    "    if question_len < 50:\n",
    "        scores = [guess[1] for guess in tfidf_guesses]\n",
    "        buzz = scores[0] / sum(scores) >= BUZZ_THRESHOLD\n",
    "        return tfidf_guesses[0][0], buzz\n",
    "\n",
    "    return dan_guesses, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAN_BUZZ_NUM_GUESSES = 2\n",
    "DAN_BUZZ_THRESHOLD = .6\n",
    "\n",
    "def dan_guess_and_buzz(dan_model, question_text):\n",
    "    guesses = dan_model.guess(question_text, DAN_BUZZ_NUM_GUESSES)\n",
    "    scores = [guess[1] for guess in guesses]\n",
    "    buzz = scores[0] / sum(scores) >= DAN_BUZZ_THRESHOLD\n",
    "    return guesses[0][0], buzz, scores[0] / sum(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for when we get the correct answer vs buzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    for qidx in range(50):\n",
    "        print(f\"\\nQuestion {qidx}\")\n",
    "        ans = test_data[qidx][\"page\"]\n",
    "        text_len = len(test_data[qidx][\"text\"].split(\" \"))\n",
    "        for num_words in range(30, text_len + 5, 5):\n",
    "            text = \" \".join(test_data[qidx][\"text\"].split(\" \")[:num_words])\n",
    "            guess = dan_guess_and_buzz(dan_guesser, text)\n",
    "            if guess[0] == ans or guess[1]:\n",
    "                print(\"Words: {}, Correct: {}, Buzz: {}, Confidence: {}\".format(num_words, guess[0] == ans, guess[1], guess[2]))\n",
    "                if guess[1]: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get multiple answers and check target word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/allen/.pyenv/versions/cmsc723/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "def format_type(t):\n",
    "    t = t[1:-1]\n",
    "    t = \" \".join(t.split(\"_\")[1:])\n",
    "    return t\n",
    "\n",
    "def query_types(text):\n",
    "    conn_string = \"host='localhost' dbname='allen' user='allen'\"\n",
    "    conn = psycopg2.connect(conn_string)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"select object from yagofacts where subject = '<{}>'\".format(text.replace(\"'\", \"''\")))\n",
    "\n",
    "    results = cur.fetchall()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return [format_type(r[0]) for r in results]\n",
    "\n",
    "\n",
    "def best_noun_from_subject(text):\n",
    "    tags = pos_tag(text)\n",
    "    if len(tags) == 1:\n",
    "        return tags[0][0]\n",
    "\n",
    "    # check first word for NNS\n",
    "    if tags[0][1] in [\"NNS\"]:\n",
    "        return tags[0][0]\n",
    "    \n",
    "    # check last word for NNS\n",
    "    if tags[-1][1] in [\"NNS\"]:\n",
    "        return tags[-1][0]\n",
    "    \n",
    "    # looks for first NNS\n",
    "    for t in tags:\n",
    "        if t[1] in [\"NNS\"]:\n",
    "            return t[0]\n",
    "    \n",
    "\n",
    "def best_similarity(target, answer):\n",
    "#     print(f\"target word: {target}\")\n",
    "    if target in glove.stoi:\n",
    "        target_vec = glove.vectors[glove.stoi[target]]\n",
    "    else:\n",
    "        return None\n",
    "    sim_scores = []\n",
    "    \n",
    "    yago_types = query_types(answer)\n",
    "    nouns = [best_noun_from_subject(n.split(\" \")) for n in yago_types]\n",
    "    for t in nouns:\n",
    "        if t is None: continue\n",
    "        t = t.lower()\n",
    "        if t not in glove.stoi:\n",
    "            continue\n",
    "        yago_type_vec = glove.vectors[glove.stoi[t]]\n",
    "        \n",
    "        wv1, wv2 = target_vec, yago_type_vec\n",
    "        similarity = dot(wv1,wv2)/ (sqrt(dot(wv1,wv1))*sqrt(dot(wv2,wv2)))\n",
    "        sim_scores.append(similarity)\n",
    "\n",
    "    max_score = max(sim_scores) if sim_scores else None\n",
    "    return max_score\n",
    "\n",
    "\n",
    "bs = best_similarity(\"author\", \"Francis_Bacon\")\n",
    "print(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 0\n",
      "One work by this author uses printing, gunpowder, and the\n",
      "answer: Francis_Bacon\n",
      "target: author\n",
      "[('Francis_Bacon',), ('Auguste_Comte',), ('Jean_Piaget',), ('George_Herbert_Mead',), ('Johann_Gottlieb_Fichte',)]\n",
      "[0.5132534999309095, 0.5132534999309095, 0.5132534999309095, 0.3830038598933477, 0.5132534999309095]\n",
      "\n",
      "Question 1\n",
      "One character in this play ignores news of his wife's\n",
      "answer: Tartuffe\n",
      "target: play\n",
      "[('Tartuffe',), ('Othello',), ('The_Imaginary_Invalid',), ('Cat_on_a_Hot_Tin_Roof',), ('The_Birthday_Party_(play)',)]\n",
      "[0.7768365397377778, 0.7768365397377778, 0.7768365397377778, 0.7768365397377778, 0.7768365397377778]\n",
      "\n",
      "Question 2\n",
      "Calculating a Racah W-coefficient requires knowledge of six parameters corresponding\n",
      "answer: Angular_momentum_operator\n",
      "target: quantity\n",
      "[('Angular_momentum',), ('Momentum',), ('Hamiltonian_(quantum_mechanics)',), ('Spin_(physics)',), ('Distance',)]\n",
      "[None, None, 0.2481735758742757, 0.8429100605670035, None]\n",
      "\n",
      "Question 3\n",
      "Coinage similarities caused this state's name to be appended to\n",
      "answer: Parthia\n",
      "target: state\n",
      "[('Sasanian_Empire',), ('Horus',), ('Parthia',), ('Bellerophon',), ('Parthian_Empire',)]\n",
      "[0.6455564642182694, 0.1456469280152831, 0.38723535852724683, 0.22363428803258517, 0.6455564642182694]\n",
      "\n",
      "Question 4\n",
      "A dog, sack, and pitcher stand in the center foreground\n",
      "answer: El_Greco\n",
      "target: painter\n",
      "[('Caravaggio',), ('Peter_Paul_Rubens',), ('Michelangelo',), ('El_Greco',), ('Isenheim_Altarpiece',)]\n",
      "[0.7064674954336216, 0.7064674954336216, 0.7064674954336216, 0.7064674954336216, 0.6628817781527692]\n",
      "\n",
      "Question 5\n",
      "This thinker labeled the transfer of religious authority from a\n",
      "answer: Max_Weber\n",
      "target: thinker\n",
      "[('Max_Weber',), ('Georg_Wilhelm_Friedrich_Hegel',), ('Francis_Bacon',), ('Ludwig_Wittgenstein',), ('Ralph_Waldo_Emerson',)]\n",
      "[0.45435704051163056, 0.45435704051163056, 0.45435704051163056, 0.45435704051163056, 0.45435704051163056]\n",
      "\n",
      "Question 6\n",
      "A short tract about this conflict notes that he who\n",
      "answer: German_Peasants'_War\n",
      "target: conflict\n",
      "[('Franco-Prussian_War',), ('Peloponnesian_War',), ('Hungary',), ('World_War_I',), ('Dorr_Rebellion',)]\n",
      "[0.8505781009854598, 0.8505781009854598, 0.49212087265289556, 0.8505781009854598, 0.8505781009854598]\n",
      "\n",
      "Question 7\n",
      "He's not George Gershwin, but a cycle of this composer's\n",
      "answer: Sergei_Rachmaninoff\n",
      "target: composer\n",
      "[('Sergei_Rachmaninoff',), ('Maurice_Ravel',), ('Sergei_Prokofiev',), ('Antonín_Dvořák',), ('Camille_Saint-Saëns',)]\n",
      "[0.7255138993787097, 0.7255138993787097, 0.7255138993787097, 0.7255138993787097, 0.7255138993787097]\n",
      "\n",
      "Question 8\n",
      "A serine/threonine kinase named for its role in the synthesis\n",
      "answer: Glycogen\n",
      "target: compound\n",
      "[('Glycogen',), ('Adenosine_triphosphate',), ('Urea_cycle',), ('Insulin',), ('Uracil',)]\n",
      "[None, None, None, None, None]\n",
      "\n",
      "Question 9\n",
      "In a work by this author, a picture of a\n",
      "answer: Orhan_Pamuk\n",
      "target: author\n",
      "[('Orhan_Pamuk',), ('Sylvia_Plath',), ('Nikolai_Gogol',), ('Jhumpa_Lahiri',), ('Marcel_Proust',)]\n",
      "[0.5132534999309095, 0.5132534999309095, 0.5132534999309095, 0.5132534999309095, 0.5132534999309095]\n",
      "\n",
      "Question 10\n",
      "One book by this thinker suggests that Dilthey successfully distinguished\n",
      "answer: Jürgen_Habermas\n",
      "target: thinker\n",
      "[('Jürgen_Habermas',), ('Auguste_Comte',), ('John_Dewey',), ('Pierre_Bourdieu',), ('Max_Weber',)]\n",
      "[0.45435704051163056, 0.45435704051163056, 0.45435704051163056, 0.45435704051163056, 0.45435704051163056]\n",
      "\n",
      "Question 11\n",
      "One character in this story remarks that a man is\n",
      "answer: The_Minister's_Black_Veil\n",
      "target: story\n",
      "[('Rip_Van_Winkle',), ('Edgar_Allan_Poe',), ('Albert_Camus',), ('The_Overcoat',), ('J._D._Salinger',)]\n",
      "[0.8101830664211377, 0.4523703618302977, 0.4523703618302977, 0.8101830664211377, 0.4523703618302977]\n",
      "\n",
      "Question 12\n",
      "This colony's practice of deciding local elections by who could\n",
      "answer: Virginia\n",
      "target: colony\n",
      "[('Virginia',), ('Maryland',), ('Louisiana',), ('Siege_of_Yorktown',), ('Jamestown,_Virginia',)]\n",
      "[0.27887188775298544, 0.27887188775298544, 0.4453974024999842, 0.20491346677537006, 0.37047641944022336]\n",
      "\n",
      "Question 13\n",
      "To aid in performing this process, Smalltalk and Racket make\n",
      "answer: Garbage_collection_(computer_science)\n",
      "target: process\n",
      "[('Garbage_collection_(computer_science)',), ('Compiler',), ('Data_compression',), ('Memory',), ('Regular_expression',)]\n",
      "[0.32399597608957614, None, 0.26974496095300166, None, 0.21219618177783248]\n",
      "\n",
      "Question 14\n",
      "One work by this thinker invokes Faulkner's line about Pickett's\n",
      "answer: Ta-Nehisi_Coates\n",
      "target: thinker\n",
      "[('John_Locke',), ('The_Chrysanthemum_and_the_Sword',), ('William_Graham_Sumner',), ('The_Wealth_of_Nations',), ('Portugal',)]\n",
      "[0.45435704051163056, None, 0.31552634123585915, 0.20474088417069305, 0.018856927464533626]\n"
     ]
    }
   ],
   "source": [
    "for qidx in range(15):\n",
    "    print(f\"\\nQuestion {qidx}\")\n",
    "    num_words = 100\n",
    "    text = \" \".join(test_data[qidx][\"text\"].split(\" \")[:num_words])\n",
    "    print(\" \".join(test_data[qidx][\"text\"].split(\" \")[:10]))\n",
    "\n",
    "    ans = test_data[qidx][\"page\"]\n",
    "    print(f\"answer: {ans}\")\n",
    "    \n",
    "    tword = target_word(text)\n",
    "    print(f\"target: {tword}\")\n",
    "\n",
    "    guesses = dan_guesser.guess(text, 5)\n",
    "    guesses_with_sim = []\n",
    "    sims = []\n",
    "    for g in guesses:\n",
    "        bs = best_similarity(tword, g[0])\n",
    "        guesses_with_sim.append((g[0], g[1], bs))\n",
    "        sims.append(bs)\n",
    "    print([g[:1] for g in guesses_with_sim])\n",
    "    print(sims)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rebellions in the United States',\n",
       " 'Conflicts in 1842',\n",
       " 'Conflicts in 1841',\n",
       " 'conflict 100958896',\n",
       " '19th-century rebellions']"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_types(\"Dorr_Rebellion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Conflicts', 'NNS'), ('in', 'IN'), ('1842', 'CD')]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag('Conflicts in 1842'.split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check num words in some questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(20):\n",
    "    print(len(test_data[idx][\"text\"].split(\" \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br>\n",
    "# Filter database entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = train_data + dev_data + test_data\n",
    "all_pages = [p[\"page\"] for p in all_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119247\n",
      "26877\n"
     ]
    }
   ],
   "source": [
    "print(len(all_pages))\n",
    "all_pages = list(set(all_pages))\n",
    "print(len(all_pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "    DELETE FROM yagofacts WHERE subject not in ({})\n",
    "\"\"\"\n",
    "stuff = \", \".join([\"'<{}>'\".format(item.replace(\"'\", \"''\")) for item in all_pages])\n",
    "\n",
    "with open(\"/Users/allen/Desktop/delete.sql\", \"w\") as f:\n",
    "    f.write(sql.format(stuff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmsc723",
   "language": "python",
   "name": "cmsc723"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
