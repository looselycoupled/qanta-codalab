{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "import requests\n",
    "import urllib.parse as urlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enumerate JSON Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files: 12697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/allen/Projects/wikiextractor/extracted/AA/wiki_00',\n",
       " '/Users/allen/Projects/wikiextractor/extracted/AA/wiki_01',\n",
       " '/Users/allen/Projects/wikiextractor/extracted/AA/wiki_02',\n",
       " '/Users/allen/Projects/wikiextractor/extracted/AA/wiki_03',\n",
       " '/Users/allen/Projects/wikiextractor/extracted/AA/wiki_04']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"/Users/allen/Projects/wikiextractor/extracted\"\n",
    "def files():\n",
    "    return sorted(glob(PATH + \"/*/*\"))\n",
    "\n",
    "\n",
    "print(\"Total Files: {}\".format(len(files())))\n",
    "files()[:5]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_iterator():\n",
    "    for path in files()[:2]:\n",
    "        with open(path, \"r\") as f:\n",
    "            print(path)\n",
    "            for line in f:\n",
    "                item = json.loads(line)\n",
    "                yield item\n",
    "#             for item in json.loads(f.read()):\n",
    "#                 yield item\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/allen/Projects/wikiextractor/extracted/AA/wiki_00\n",
      "/Users/allen/Projects/wikiextractor/extracted/AA/wiki_01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stuff = list(get_objects())\n",
    "len(stuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '615',\n",
       " 'url': 'https://en.wikipedia.org/wiki?curid=615',\n",
       " 'title': 'American Football Conference',\n",
       " 'text': 'American Football Conference\\n\\nThe American Football Conference (AFC) is one of the two conferences of the National Football League (NFL), the highest professional level of American football in the United States. This conference and its counterpart, the National Football Conference (NFC), currently contain 16 teams each, making up the 32 teams of the NFL. Both conferences were created as part of the 1970 merger with the rival American Football League (AFL), with all ten of the former AFL teams and three NFL teams forming the AFC, and the remaining thirteen NFL clubs forming the NFC. A series of league expansions and division realignments have occurred since the merger, thus making the current total 16 clubs per each conference.\\n\\nCurrent teams.\\nSince 2002, like the NFC, the AFC has 16 teams, organized into four divisions each with four teams: East, North, South and West.\\n\\nSeason structure.\\nCurrently, the thirteen opponents each team faces over the 16-game regular season schedule are set using a pre-determined formula:\\n\\nEach AFC team plays the other teams in their respective division twice (home and away) during the regular season, in addition to 10 other games assigned to their schedule by the NFL. Two of these games are assigned on the basis of a particular team\\'s final divisional standing from the previous season. The remaining 8 games are split between the roster of two other NFL divisions. This assignment shifts each year and will follow a standard cycle. Using the 2012 regular season schedule as an example, each team in the AFC West plays against every team in the AFC North and NFC South. In this way, non-divisional competition will be mostly among common opponents – the exception being the two games assigned based on the team\\'s prior-season divisional standing.\\n\\nAt the end of each season, the winner of each division, in addition to the two remaining conference teams with the highest regular season records, proceed into the playoffs. These teams consist of the four division winners and the top two wild card teams. The AFC playoffs culminate in the AFC Championship Game with the winner receiving the Lamar Hunt Trophy. The AFC Champion then plays the NFC Champion in the Super Bowl.\\n\\nHistory.\\nBoth the AFC and the NFC were created after the NFL merged with the American Football League (AFL) in 1970. The AFL began play in 1960 with eight teams, and added two more expansion clubs (the Miami Dolphins in 1966 and the Cincinnati Bengals in 1968) before the merger. In order to equalize the number of teams in each conference, three NFL teams that predated the AFL\\'s launch (the Cleveland Browns, Pittsburgh Steelers, and the then-Baltimore Colts) joined the ten former AFL teams to form the AFC. The two AFL divisions AFL East and AFL West were more or less intact, while the Century Division, in which the Browns and the Steelers had played since 1967, was moved from the NFL to become the new AFC Central.\\n\\nSince the merger, five expansion teams have joined the AFC and two have left, thus making the current total 16. When the Seattle Seahawks and the Tampa Bay Buccaneers joined the league in 1976, they were temporarily placed in the NFC and AFC respectively. This arrangement lasted for one season only before the two teams switched conferences. The Seahawks eventually returned to the NFC as a result of the 2002 realignment. The expansion Jacksonville Jaguars joined the AFC in 1995. There have been five teams that have relocated at least once. In 1984, the Baltimore Colts relocated to Indianapolis in 1984. In 1995, the Cleveland Browns had attempted to move to Baltimore; the resulting dispute between Cleveland and the team led to Modell establishing the Baltimore Ravens with the players and personnel from the Browns, while the Browns were placed in suspended operations before they were reinstated by the NFL.\\n\\nIn California, the Oakland Raiders relocated to Los Angeles in 1982, and back to Oakland in 1995, while the San Diego Chargers moved to Los Angeles in 2017.\\n\\nThe Houston Oilers moved to Tennessee in 1997, where they were renamed the Tennessee Oilers. The team would change its name again, two years later, to the Tennessee Titans.\\n\\nThe NFL would again expand in 2002, adding the Houston Texans to the AFC.\\n\\nBetween 1995 and 2017, the AFC has sent less than half of the different teams with 7 of the 16 different teams to the Super Bowl. New England Patriots (9 times), Denver Broncos (4 times), Pittsburgh Steelers (4 times), Baltimore Ravens (2 times), Indianapolis Colts (2 times), Oakland Raiders (1 time), and Tennessee Titans (1 time). By contrast, the NFC has sent 13 of the 16 different teams during that same time frame with only the Detroit Lions, Minnesota Vikings, and Washington Redskins missing out on an appearance in the Super Bowl. 15 of the last 17 AFC champions have started one of just three quarterbacks - Tom Brady, Peyton Manning, and Ben Roethlisberger - in the Super Bowl.\\n\\nLogo.\\nThe merged league created a new logo for the AFC that took elements of the old AFL logo, specifically the \"A\" and the six stars surrounding it. The AFC logo basically remained unchanged from 1970 to 2009. The 2010 NFL season introduced an updated AFC logo, with the most notable revision being the removal of two stars (leaving four representing the four divisions of the AFC), and moving the stars inside the letter, similar to the NFC logo.\\n'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stuff[33]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Section Title Only \n",
    "Based on length of paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Anarchism',\n",
       " 'Etymology and terminology.',\n",
       " 'History.',\n",
       " 'Origins.',\n",
       " 'First International and the Paris Commune.',\n",
       " 'Organised labour.',\n",
       " 'Propaganda of the deed and illegalism.',\n",
       " 'Russian Revolution and other uprisings of the 1910s.',\n",
       " 'Conflicts with European fascist regimes.',\n",
       " 'Spanish Revolution.',\n",
       " 'Post-war years.',\n",
       " 'Contemporary anarchism.',\n",
       " 'Anarchist schools of thought.',\n",
       " 'Mutualism.',\n",
       " 'Social anarchism.',\n",
       " 'Collectivist anarchism.',\n",
       " 'Anarcho-communism.',\n",
       " 'Anarcho-syndicalism.',\n",
       " 'Individualist anarchism.',\n",
       " 'Post-classical anarchist schools of thought.',\n",
       " 'Internal issues and debates.',\n",
       " 'Topics of interest.',\n",
       " 'Free love.',\n",
       " 'Libertarian education and freethought.',\n",
       " 'Criticisms.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split text into list of paragraphs based on line break\n",
    "text = [ii for ii in stuff[0][\"text\"].strip().split(\"\\n\") if ii.strip()]\n",
    "\n",
    "\n",
    "# find section title \n",
    "MIN_PARA_LEN = 10\n",
    "section_titles = [ii for ii in text if len(ii.split()) <= MIN_PARA_LEN]\n",
    "section_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create iter for paragraphs in Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/allen/Projects/wikiextractor/extracted/AA/wiki_00\n",
      "Anarchism Anarchism is a political philosophy that advocates self-governed societies based on voluntary institutions. These are often described as stateless societies, although several authors have defined them more specifically as institutions based on non-hierarchical or free associations. Anarchism holds the state to be undesirable, unnecessary and harmful.\n",
      "While opposition to the state is central, anarchism specifically entails opposing authority or hierarchical organisation in the conduct of all human relations. Anarchism is usually considered a far-left ideology and much of anarchist economics and anarchist legal philosophy reflects anti-authoritarian interpretations of communism, collectivism, syndicalism, mutualism or participatory economics.\n",
      "Anarchism does not offer a fixed body of doctrine from a single particular world view, instead fluxing and flowing as a philosophy. Many types and traditions of anarchism exist, not all of which are mutually exclusive. Anarchist schools of thought can differ fundamentally, supporting anything from extreme individualism to complete collectivism. Strains of anarchism have often been divided into the categories of social and individualist anarchism or similar dual classifications.\n",
      "Etymology and terminology. The word \"anarchism\" is composed from the word \"anarchy\" and the suffix -ism, themselves derived respectively from the Greek , i.e. \"anarchy\" (from , \"anarchos\", meaning \"one without rulers\"; from the privative prefix ἀν- (\"an-\", i.e. \"without\") and , \"archos\", i.e. \"leader\", \"ruler\"; (cf. \"archon\" or , \"arkhē\", i.e. \"authority\", \"sovereignty\", \"realm\", \"magistracy\")) and the suffix or (\"-ismos\", \"-isma\", from the verbal infinitive suffix , \"-izein\"). The first known use of this word was in 1539. Various factions within the French Revolution labelled opponents as anarchists (as Maximilien Robespierre did the Hébertists) although few shared many views of later anarchists. There would be many revolutionaries of the early nineteenth century who contributed to the anarchist doctrines of the next generation, such as William Godwin and Wilhelm Weitling, but they did not use the word \"anarchist\" or \"anarchism\" in describing themselves or their beliefs.\n",
      "The first political philosopher to call himself an anarchist was Pierre-Joseph Proudhon, marking the formal birth of anarchism in the mid-nineteenth century. Since the 1890s and beginning in France, the term \"libertarianism\" has often been used as a synonym for anarchism and was used almost exclusively in this sense until the 1950s in the United States, though its use as a synonym is still common outside the United States. On the other hand, some use libertarianism to refer to individualistic free market philosophy only, referring to free market anarchism as libertarian anarchism.\n"
     ]
    }
   ],
   "source": [
    "def wikidata_iterator(path, output=\"text\"):\n",
    "\n",
    "    def doc_iterator(path):\n",
    "        files = sorted(glob(path + \"/*/*\"))\n",
    "\n",
    "        for path in files[:2]:\n",
    "            with open(path, \"r\") as f:\n",
    "                print(path)\n",
    "                for line in f:\n",
    "                    item = json.loads(line)\n",
    "                    yield item\n",
    "\n",
    "    def para_iterator(doc):\n",
    "        MIN_LENGTH = 300\n",
    "        text = [ii for ii in doc.strip().split(\"\\n\") if ii.strip()]\n",
    "\n",
    "        too_small = \"\"\n",
    "        for para in text:\n",
    "            if len(para) < MIN_LENGTH:\n",
    "                too_small = too_small + \" \" + para\n",
    "                continue\n",
    "\n",
    "            yield (too_small + \" \" + para).strip()\n",
    "            too_small = \"\"\n",
    "\n",
    "    def fetch_title(url):\n",
    "        api_url = \"https://en.wikipedia.org/w/api.php?action=query&prop=info&pageids={}&inprop=url&format=json\"\n",
    "\n",
    "        parsed = urlparse.urlparse(url)\n",
    "        curid = urlparse.parse_qs(parsed.query)[\"curid\"][0]\n",
    "\n",
    "        response = requests.get(api_url.format(curid))\n",
    "        data = response.json()\n",
    "        canonicalurl = data[\"query\"][\"pages\"][curid][\"canonicalurl\"]\n",
    "        return canonicalurl.split(\"/\")[-1]\n",
    "\n",
    "    for doc in doc_iterator(path):\n",
    "        try:\n",
    "            ans = fetch_title(doc[\"url\"])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "        for para in para_iterator(doc[\"text\"]):\n",
    "            if output == \"text\": \n",
    "                yield para\n",
    "                \n",
    "            if output == \"ans\":\n",
    "                yield ans\n",
    "            \n",
    "            if output == \"both\":\n",
    "                yield ans, para\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try something fancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikidataIterator(object):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.i_to_ans = {}\n",
    "\n",
    "    def _doc_iterator(self, path):\n",
    "        files = sorted(glob(path + \"/*/*\"))\n",
    "\n",
    "        for path in files[:10]:\n",
    "            with open(path, \"r\") as f:\n",
    "                print(path)\n",
    "                for line in f:\n",
    "                    item = json.loads(line)\n",
    "                    yield item\n",
    "\n",
    "    def _para_iterator(self, doc):\n",
    "        MIN_LENGTH = 300\n",
    "        text = [ii for ii in doc.strip().split(\"\\n\") if ii.strip()]\n",
    "\n",
    "        too_small = \"\"\n",
    "        for para in text:\n",
    "            if len(para) < MIN_LENGTH:\n",
    "                too_small = too_small + \" \" + para\n",
    "                continue\n",
    "\n",
    "            yield (too_small + \" \" + para).strip()\n",
    "            too_small = \"\"\n",
    "\n",
    "    def _fetch_title(self, url):\n",
    "        api_url = \"https://en.wikipedia.org/w/api.php?action=query&prop=info&pageids={}&inprop=url&format=json\"\n",
    "\n",
    "        parsed = urlparse.urlparse(url)\n",
    "        curid = urlparse.parse_qs(parsed.query)[\"curid\"][0]\n",
    "\n",
    "        response = requests.get(api_url.format(curid))\n",
    "        data = response.json()\n",
    "        canonicalurl = data[\"query\"][\"pages\"][curid][\"canonicalurl\"]\n",
    "        return canonicalurl.split(\"/\")[-1]\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def docs(self):\n",
    "        counter = 0\n",
    "        for doc in self._doc_iterator(self.path):\n",
    "            try:\n",
    "                ans = self._fetch_title(doc[\"url\"])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "\n",
    "            for para in self._para_iterator(doc[\"text\"]):\n",
    "                self.i_to_ans[counter] = ans\n",
    "                counter += 1\n",
    "                yield para\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFIDF():\n",
    "    \n",
    "    def init(self):\n",
    "        self.i_to_ans = None\n",
    "    \n",
    "    def train(self, path, ngram_range=(1, 1), min_df=1, max_df=.95):\n",
    "        wikidata = WikidataIterator(path)\n",
    "        \n",
    "        vectorizer_kwargs = {\n",
    "            'ngram_range': ngram_range,\n",
    "            'min_df': min_df,\n",
    "            'max_df': max_df\n",
    "        }\n",
    "        start = time.time()\n",
    "        self.tfidf_vectorizer = TfidfVectorizer(**vectorizer_kwargs).fit(wikidata.docs)\n",
    "        elapsed = int(time.time() - start)\n",
    "        print(\"INFO: fit completed in {} seconds\".format(elapsed))\n",
    "        \n",
    "        start = time.time()\n",
    "        self.tfidf_matrix = self.tfidf_vectorizer.transform(wikidata.docs)\n",
    "        elapsed = int(time.time() - start)\n",
    "        print(\"INFO: transform completed in {} seconds\".format(elapsed))\n",
    "        \n",
    "        self.i_to_ans = wikidata.i_to_ans\n",
    "\n",
    "    def guess(self, questions, max_n_guesses=2):\n",
    "        representations = self.tfidf_vectorizer.transform(questions)\n",
    "        guess_matrix = self.tfidf_matrix.dot(representations.T).T\n",
    "        guess_indices = (-guess_matrix).toarray().argsort(axis=1)[:, 0:max_n_guesses]\n",
    "        guesses = []\n",
    "        for i in range(len(questions)):\n",
    "            idxs = guess_indices[i]\n",
    "            guesses.append([(self.i_to_ans[j], guess_matrix[i, j]) for j in idxs])\n",
    "\n",
    "        return guesses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/allen/Projects/wikiextractor/extracted/AA/wiki_00\n",
      "/Users/allen/Projects/wikiextractor/extracted/AA/wiki_01\n",
      "/Users/allen/Projects/wikiextractor/extracted/AA/wiki_02\n",
      "/Users/allen/Projects/wikiextractor/extracted/AA/wiki_03\n",
      "/Users/allen/Projects/wikiextractor/extracted/AA/wiki_04\n",
      "/Users/allen/Projects/wikiextractor/extracted/AA/wiki_05\n",
      "/Users/allen/Projects/wikiextractor/extracted/AA/wiki_06\n",
      "/Users/allen/Projects/wikiextractor/extracted/AA/wiki_07\n",
      "/Users/allen/Projects/wikiextractor/extracted/AA/wiki_08\n",
      "/Users/allen/Projects/wikiextractor/extracted/AA/wiki_09\n",
      "INFO: fit completed in 95 seconds\n",
      "/Users/allen/Projects/wikiextractor/extracted/AA/wiki_00\n",
      "/Users/allen/Projects/wikiextractor/extracted/AA/wiki_01\n",
      "/Users/allen/Projects/wikiextractor/extracted/AA/wiki_02\n",
      "/Users/allen/Projects/wikiextractor/extracted/AA/wiki_03\n",
      "/Users/allen/Projects/wikiextractor/extracted/AA/wiki_04\n",
      "/Users/allen/Projects/wikiextractor/extracted/AA/wiki_05\n",
      "/Users/allen/Projects/wikiextractor/extracted/AA/wiki_06\n",
      "/Users/allen/Projects/wikiextractor/extracted/AA/wiki_07\n",
      "/Users/allen/Projects/wikiextractor/extracted/AA/wiki_08\n",
      "/Users/allen/Projects/wikiextractor/extracted/AA/wiki_09\n",
      "INFO: transform completed in 94 seconds\n"
     ]
    }
   ],
   "source": [
    "model = TFIDF()\n",
    "model.train(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.215555555555557"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files()) * 8 / 60 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files: 12697\n"
     ]
    }
   ],
   "source": [
    "num_files = len(files())\n",
    "print(\"Files: {}\".format(num_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26529"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.tfidf_vectorizer.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2808"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.i_to_ans.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/allen/Projects/wikiextractor/extracted/AA/wiki_00\n",
      "/Users/allen/Projects/wikiextractor/extracted/AA/wiki_01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2808, 2808)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikidata = WikidataIterator(PATH)\n",
    "docs = [1 for _ in wikidata.docs]\n",
    "len(docs), len(wikidata.i_to_ans.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5269444444444447"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12697 / 60 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmsc723",
   "language": "python",
   "name": "cmsc723"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
